{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRb9IMl3jQS",
        "outputId": "336b0357-4923-485a-9153-c2c400b64a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "path_to_pth_file = \"/content/mnist_cnn_model_simba.pth\"\n",
        "model = torch.load(path_to_pth_file)\n",
        "\n",
        "import keras.datasets.mnist as mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "conv1_wt=model['conv1.weight']\n",
        "conv1_bias=model['conv1.bias']\n",
        "fc1_wt=model['fc1.weight']\n",
        "fc1_bias=model['fc1.bias']\n",
        "fc2_wt=model['fc2.weight']\n",
        "fc2_bias=model['fc2.bias']\n",
        "\n",
        "\n",
        "conv1_wt=conv1_wt.numpy()\n",
        "conv1_bias=conv1_bias.numpy()\n",
        "fc1_wt=fc1_wt.numpy()\n",
        "fc1_bias=fc1_bias.numpy()\n",
        "fc2_wt=fc2_wt.numpy()\n",
        "fc2_bias=fc2_bias.numpy()\n",
        "\n",
        "test_images = test_images/255.0"
      ],
      "metadata": {
        "id": "LLfnMjpb3z-S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_2d(test_images, conv_wt, conv_bias):\n",
        "    conv_outputs = []\n",
        "    imgs = np.expand_dims(test_images, axis=1)\n",
        "    batch_size, in_channels, in_height, in_width = imgs.shape\n",
        "    out_channels, _, kernel_height, kernel_width = conv_wt.shape\n",
        "    out_height = in_height - kernel_height + 1\n",
        "    out_width = in_width - kernel_width + 1\n",
        "    for img in imgs:\n",
        "        img_conv_outputs = []\n",
        "        for filter, b in zip(conv_wt, conv_bias):\n",
        "            conv_output = np.zeros((out_height, out_width))\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    roi = img[:, i:i+kernel_height, j:j+kernel_width]\n",
        "                    conv_output[i, j] = np.sum(roi * filter) + b\n",
        "            img_conv_outputs.append(conv_output)\n",
        "\n",
        "        conv_outputs.append(img_conv_outputs)\n",
        "\n",
        "    conv_outputs = np.array(conv_outputs)\n",
        "    return conv_outputs"
      ],
      "metadata": {
        "id": "Ff0Vi68V38GA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_2d(test_images[0:1], conv1_wt, conv1_bias).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2JtZwIb4V_n",
        "outputId": "f64bc8ce-7be2-4576-bb17-00328a0b5242"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 32, 26, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(input_data):\n",
        "    return np.maximum(input_data, 0)\n",
        "\n",
        "def fully_connected(input_data, weights, bias):\n",
        "    return np.matmul(input_data, weights.T) + bias\n",
        "\n",
        "def softmax(input_data):\n",
        "    exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True))\n",
        "    return exp_values / np.sum(exp_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "nFXeWh_239gH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_pool(conv_out, kernel_size):\n",
        "    batch_size, channels, height, width = conv_out.shape\n",
        "    out_height = height // kernel_size\n",
        "    out_width = width // kernel_size\n",
        "\n",
        "    output = np.zeros((batch_size, channels, out_height, out_width))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for c in range(channels):\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    max_val = np.max(conv_out[b, c, kernel_size*i: kernel_size*(i+1), kernel_size*j: kernel_size*(j+1)])\n",
        "                    output[b, c, i, j] = max_val\n",
        "    return output"
      ],
      "metadata": {
        "id": "CLiDksF639mv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def forward_pass(input_data, conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias):\n",
        "\n",
        "    print(\"input: \", input_data.shape)\n",
        "\n",
        "    conv_output = conv_2d(input_data, conv1_wt, conv1_bias)\n",
        "    print(\"convolution: \", conv_output.shape)\n",
        "\n",
        "    conv_output = relu(conv_output)\n",
        "    print(\"activation: \", conv_output.shape)\n",
        "\n",
        "    pooled_output = max_pool(conv_output, kernel_size=2)\n",
        "    print(\"max pooling: \", pooled_output.shape)\n",
        "\n",
        "    flattened_output = pooled_output.reshape(len(input_data), -1)\n",
        "    print(\"flattened_output: \", flattened_output.shape)\n",
        "\n",
        "\n",
        "    fc1_output = fully_connected(flattened_output, fc1_wt, fc1_bias)\n",
        "    print(\"fully connected layer 1:\", fc1_output.shape)\n",
        "\n",
        "    fc1_output = relu(fc1_output)\n",
        "\n",
        "    fc2_output = fully_connected(fc1_output, fc2_wt, fc2_bias)\n",
        "    print(\"fully connected layer 2:\", fc2_output.shape)\n",
        "\n",
        "    probabilities = softmax(fc2_output)\n",
        "\n",
        "    predicted_classes = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ],
      "metadata": {
        "id": "XVBmiCDv4Cup"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = forward_pass(test_images[0:100], conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias)\n",
        "\n",
        "print(\"Predicted values: \", pred[:10])\n",
        "print(\"Test Labels     : \", test_labels[:10])\n",
        "print(\"accuracy: \", sum(pred[:100] == test_labels[:100])/len(pred[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMIW06w4ENq",
        "outputId": "bd95a810-a846-4f22-90b0-f4cc31a610d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  (100, 28, 28)\n",
            "convolution:  (100, 32, 26, 26)\n",
            "activation:  (100, 32, 26, 26)\n",
            "max pooling:  (100, 32, 13, 13)\n",
            "flattened_output:  (100, 5408)\n",
            "fully connected layer 1: (100, 64)\n",
            "fully connected layer 2: (100, 10)\n",
            "Predicted values:  [7 2 1 0 4 1 4 9 6 9]\n",
            "Test Labels     :  [7 2 1 0 4 1 4 9 5 9]\n",
            "accuracy:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hex_to_float_8bit(hex_value):\n",
        "    int_value = int(hex_value, 16)\n",
        "    float_value = int_value / 255.0\n",
        "    return float_value"
      ],
      "metadata": {
        "id": "xOShEZ0j5MlR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convol_output(flattened_arr):\n",
        "  hex_val = []\n",
        "  for i in range(0, len(flattened_arr), 2):\n",
        "    a = flattened_arr[i]\n",
        "    b = flattened_arr[i+1]\n",
        "    hex_val.extend([a+b])\n",
        "\n",
        "  #print(hex_val)\n",
        "  conv_out = []\n",
        "  for i in range(len(hex_val)):\n",
        "    conv_out.append(hex_to_float_8bit(hex_val[i]))\n",
        "  print(len(conv_out))\n",
        "  conv_out = np.array(conv_out)\n",
        "  conv_out = conv_out.reshape((1, 32, 26, 26))\n",
        "  return conv_out"
      ],
      "metadata": {
        "id": "AiadsUvg5RGY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_arr = ['0','b','1','d']\n",
        "convolution_outputs = convol_output(flattened_arr)\n",
        "convolution_outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "QICFQ0k35XRz",
        "outputId": "cffb555b-2e93-42df-ccd3-9fa813c6c68f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 2 into shape (1,32,28,28)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a0b327a865c9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflattened_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvolution_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvol_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconvolution_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-78a5a6da8fd4>\u001b[0m in \u001b[0;36mconvol_output\u001b[0;34m(flattened_arr)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_float_8bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,32,28,28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def forward_pass_simba(input_data,flattened_arr, conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias):\n",
        "\n",
        "    print(\"input: \", flattened_arr.shape)\n",
        "\n",
        "    conv_output = convol_output(flattened_arr)\n",
        "    print(\"convolution: \", conv_output.shape)\n",
        "\n",
        "    conv_output = relu(conv_output)\n",
        "    print(\"activation: \", conv_output.shape)\n",
        "\n",
        "    pooled_output = max_pool(conv_output, kernel_size=2)\n",
        "    print(\"max pooling: \", pooled_output.shape)\n",
        "\n",
        "    flattened_output = pooled_output.reshape(len(input_data), -1)\n",
        "    print(\"flattened_output: \", flattened_output.shape)\n",
        "\n",
        "\n",
        "    fc1_output = fully_connected(flattened_output, fc1_wt, fc1_bias)\n",
        "    print(\"fully connected layer 1:\", fc1_output.shape)\n",
        "\n",
        "    fc1_output = relu(fc1_output)\n",
        "\n",
        "    fc2_output = fully_connected(fc1_output, fc2_wt, fc2_bias)\n",
        "    print(\"fully connected layer 2:\", fc2_output.shape)\n",
        "\n",
        "    probabilities = softmax(fc2_output)\n",
        "\n",
        "    predicted_classes = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ],
      "metadata": {
        "id": "4vI0gme_5BMg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_arr = []\n",
        "for i in range(21632*2):\n",
        "  flattened_arr.append('01')\n",
        "flattened_arr = np.array(flattened_arr)\n",
        "len(flattened_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgKYcdZp_5wT",
        "outputId": "78e8c272-0804-4dfc-a800-cc622d8fff27"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43264"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = forward_pass_simba(test_images[0:1], flattened_arr, conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias)\n",
        "\n",
        "print(\"Predicted values: \", pred[:1])\n",
        "print(\"Test Labels     : \", test_labels[:1])\n",
        "print(\"accuracy: \", sum(pred[:1] == test_labels[:1])/len(pred[:1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zPAoHba4T7d",
        "outputId": "0363ef87-9f7d-44dc-d7b3-4ed321b4099a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  (43264,)\n",
            "21632\n",
            "convolution:  (1, 32, 26, 26)\n",
            "activation:  (1, 32, 26, 26)\n",
            "max pooling:  (1, 32, 13, 13)\n",
            "flattened_output:  (1, 5408)\n",
            "fully connected layer 1: (1, 64)\n",
            "fully connected layer 2: (1, 10)\n",
            "Predicted values:  [2]\n",
            "Test Labels     :  [7]\n",
            "accuracy:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.zeros(21632)\n",
        "print(arr.shape)\n",
        "arr = arr.reshape((1,32,26,26))\n",
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL87czLB49Jn",
        "outputId": "423c5ddb-78a6-429c-cc72-9da4999c8a3f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21632,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 32, 26, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvBM3PInA2Zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}