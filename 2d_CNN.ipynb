{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MJLoeke4mU2L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "path_to_pth_file = \"/content/mnist_cnn_model_simba.pth\"\n",
        "model = torch.load(path_to_pth_file)\n",
        "\n",
        "import keras.datasets.mnist as mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "conv1_wt=model['conv1.weight']\n",
        "conv1_bias=model['conv1.bias']\n",
        "fc1_wt=model['fc1.weight']\n",
        "fc1_bias=model['fc1.bias']\n",
        "fc2_wt=model['fc2.weight']\n",
        "fc2_bias=model['fc2.bias']\n",
        "\n",
        "conv1_wt=conv1_wt.numpy()\n",
        "conv1_bias=conv1_bias.numpy()\n",
        "fc1_wt=fc1_wt.numpy()\n",
        "fc1_bias=fc1_bias.numpy()\n",
        "fc2_wt=fc2_wt.numpy()\n",
        "fc2_bias=fc2_bias.numpy()\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "ZpDXBqSgnQ-y"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_2d(test_images, conv_wt, conv_bias):\n",
        "    conv_outputs = []\n",
        "    imgs = np.expand_dims(test_images, axis=1)\n",
        "    batch_size, in_channels, in_height, in_width = imgs.shape\n",
        "    out_channels, _, kernel_height, kernel_width = conv_wt.shape\n",
        "    out_height = in_height - kernel_height + 1\n",
        "    out_width = in_width - kernel_width + 1\n",
        "    for img in imgs:\n",
        "        img_conv_outputs = []\n",
        "        for filter, b in zip(conv_wt, conv_bias):\n",
        "            conv_output = np.zeros((out_height, out_width))\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    roi = img[:, i:i+kernel_height, j:j+kernel_width]\n",
        "                    conv_output[i, j] = np.sum(roi * filter) + b\n",
        "            img_conv_outputs.append(conv_output)\n",
        "\n",
        "        conv_outputs.append(img_conv_outputs)\n",
        "\n",
        "    conv_outputs = np.array(conv_outputs)\n",
        "    return conv_outputs"
      ],
      "metadata": {
        "id": "FYVzEA_3nTDN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(input_data):\n",
        "    return np.maximum(input_data, 0)\n",
        "\n",
        "def fully_connected(input_data, weights, bias):\n",
        "    return np.matmul(input_data, weights.T) + bias\n",
        "\n",
        "def softmax(input_data):\n",
        "    exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True))\n",
        "    return exp_values / np.sum(exp_values, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "69FCcokVnVUE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_pool(conv_out, kernel_size):\n",
        "    batch_size, channels, height, width = conv_out.shape\n",
        "    out_height = height // kernel_size\n",
        "    out_width = width // kernel_size\n",
        "\n",
        "    output = np.zeros((batch_size, channels, out_height, out_width))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for c in range(channels):\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    max_val = np.max(conv_out[b, c, kernel_size*i: kernel_size*(i+1), kernel_size*j: kernel_size*(j+1)])\n",
        "                    output[b, c, i, j] = max_val\n",
        "    return output"
      ],
      "metadata": {
        "id": "v05X8U6jnXNQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def forward_pass(input_data, conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias):\n",
        "\n",
        "    print(\"input: \", input_data.shape)\n",
        "\n",
        "    conv_output = conv_2d(input_data, conv1_wt, conv1_bias)\n",
        "    print(\"convolution: \", conv_output.shape)\n",
        "\n",
        "    conv_output = relu(conv_output)\n",
        "    print(\"activation: \", conv_output.shape)\n",
        "\n",
        "    pooled_output = max_pool(conv_output, kernel_size=2)\n",
        "    print(\"max pooling: \", pooled_output.shape)\n",
        "\n",
        "    flattened_output = pooled_output.reshape(len(input_data), -1)\n",
        "    print(\"flattened_output: \", flattened_output.shape)\n",
        "\n",
        "\n",
        "    fc1_output = fully_connected(flattened_output, fc1_wt, fc1_bias)\n",
        "    print(\"fully connected layer 1:\", fc1_output.shape)\n",
        "\n",
        "    fc1_output = relu(fc1_output)\n",
        "\n",
        "    fc2_output = fully_connected(fc1_output, fc2_wt, fc2_bias)\n",
        "    print(\"fully connected layer 2:\", fc2_output.shape)\n",
        "\n",
        "    probabilities = softmax(fc2_output)\n",
        "\n",
        "    predicted_classes = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ],
      "metadata": {
        "id": "4AfYljkenaGE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = forward_pass(test_images[:100], conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias)\n",
        "\n",
        "print(\"Predicted values: \", pred[:10])\n",
        "print(\"Test Labels     : \", test_labels[:10])\n",
        "print(\"accuracy: \", sum(pred[:100] == test_labels[:100])/len(pred[:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz27Sn77n15d",
        "outputId": "8b94aba7-b695-4054-cc8f-44e88fabe4b4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  (100, 28, 28)\n",
            "convolution  (100, 32, 26, 26)\n",
            "activation:  (100, 32, 26, 26)\n",
            "max pooling:  (100, 32, 13, 13)\n",
            "flattened_output:  (100, 5408)\n",
            "fully connected layer 1: (100, 64)\n",
            "fully connected layer 2: (100, 10)\n",
            "Predicted values:  [7 2 1 0 4 1 4 9 6 9]\n",
            "Test Labels     :  [7 2 1 0 4 1 4 9 5 9]\n",
            "accuracy:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXBb7fl8ofql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}