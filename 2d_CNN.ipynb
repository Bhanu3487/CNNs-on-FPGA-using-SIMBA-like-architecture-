{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MJLoeke4mU2L"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/mnist_cnn_model_simba.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path_to_pth_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/mnist_cnn_model_simba.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_pth_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmnist\u001b[39;00m\n\u001b[0;32m      6\u001b[0m (train_images, train_labels), (test_images, test_labels) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
            "File \u001b[1;32mc:\\Users\\bhanu\\OneDrive\\Desktop\\ml_A2\\.conda\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\bhanu\\OneDrive\\Desktop\\ml_A2\\.conda\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\bhanu\\OneDrive\\Desktop\\ml_A2\\.conda\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/mnist_cnn_model_simba.pth'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "path_to_pth_file = \"/content/mnist_cnn_model_simba.pth\"\n",
        "model = torch.load(path_to_pth_file)\n",
        "\n",
        "import keras.datasets.mnist as mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZpDXBqSgnQ-y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "conv1_wt=model['conv1.weight']\n",
        "conv1_bias=model['conv1.bias']\n",
        "fc1_wt=model['fc1.weight']\n",
        "fc1_bias=model['fc1.bias']\n",
        "fc2_wt=model['fc2.weight']\n",
        "fc2_bias=model['fc2.bias']\n",
        "\n",
        "conv1_wt = conv1_wt/255\n",
        "\n",
        "conv1_wt=conv1_wt.numpy()\n",
        "conv1_bias=conv1_bias.numpy()\n",
        "fc1_wt=fc1_wt.numpy()\n",
        "fc1_bias=fc1_bias.numpy()\n",
        "fc2_wt=fc2_wt.numpy()\n",
        "fc2_bias=fc2_bias.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FYVzEA_3nTDN"
      },
      "outputs": [],
      "source": [
        "def conv_2d(test_images, conv_wt, conv_bias):\n",
        "    conv_outputs = []\n",
        "    imgs = np.expand_dims(test_images, axis=1)\n",
        "    batch_size, in_channels, in_height, in_width = imgs.shape\n",
        "    out_channels, _, kernel_height, kernel_width = conv_wt.shape\n",
        "    out_height = in_height - kernel_height + 1\n",
        "    out_width = in_width - kernel_width + 1\n",
        "    for img in imgs:\n",
        "        img_conv_outputs = []\n",
        "        for filter, b in zip(conv_wt, conv_bias):\n",
        "            conv_output = np.zeros((out_height, out_width))\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    roi = img[:, i:i+kernel_height, j:j+kernel_width]\n",
        "                    conv_output[i, j] = np.sum(roi * filter) + b\n",
        "            img_conv_outputs.append(conv_output)\n",
        "\n",
        "        conv_outputs.append(img_conv_outputs)\n",
        "\n",
        "    conv_outputs = np.array(conv_outputs)\n",
        "    return conv_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "69FCcokVnVUE"
      },
      "outputs": [],
      "source": [
        "def relu(input_data):\n",
        "    return np.maximum(input_data, 0)\n",
        "\n",
        "def fully_connected(input_data, weights, bias):\n",
        "    return np.matmul(input_data, weights.T) + bias\n",
        "\n",
        "def softmax(input_data):\n",
        "    exp_values = np.exp(input_data - np.max(input_data, axis=1, keepdims=True))\n",
        "    return exp_values / np.sum(exp_values, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "v05X8U6jnXNQ"
      },
      "outputs": [],
      "source": [
        "def max_pool(conv_out, kernel_size):\n",
        "    batch_size, channels, height, width = conv_out.shape\n",
        "    out_height = height // kernel_size\n",
        "    out_width = width // kernel_size\n",
        "\n",
        "    output = np.zeros((batch_size, channels, out_height, out_width))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for c in range(channels):\n",
        "            for i in range(out_height):\n",
        "                for j in range(out_width):\n",
        "                    max_val = np.max(conv_out[b, c, kernel_size*i: kernel_size*(i+1), kernel_size*j: kernel_size*(j+1)])\n",
        "                    output[b, c, i, j] = max_val\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4AfYljkenaGE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def forward_pass(input_data, conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias):\n",
        "\n",
        "    print(\"input: \", input_data.shape)\n",
        "\n",
        "    conv_output = conv_2d(input_data, conv1_wt, conv1_bias)\n",
        "    print(\"convolution: \", conv_output.shape)\n",
        "\n",
        "    conv_output = relu(conv_output)\n",
        "    print(\"activation: \", conv_output.shape)\n",
        "\n",
        "    pooled_output = max_pool(conv_output, kernel_size=2)\n",
        "    print(\"max pooling: \", pooled_output.shape)\n",
        "\n",
        "    flattened_output = pooled_output.reshape(len(input_data), -1)\n",
        "    print(\"flattened_output: \", flattened_output.shape)\n",
        "\n",
        "\n",
        "    fc1_output = fully_connected(flattened_output, fc1_wt, fc1_bias)\n",
        "    print(\"fully connected layer 1:\", fc1_output.shape)\n",
        "\n",
        "    fc1_output = relu(fc1_output)\n",
        "\n",
        "    fc2_output = fully_connected(fc1_output, fc2_wt, fc2_bias)\n",
        "    print(\"fully connected layer 2:\", fc2_output.shape)\n",
        "\n",
        "    probabilities = softmax(fc2_output)\n",
        "\n",
        "    predicted_classes = np.argmax(probabilities, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz27Sn77n15d",
        "outputId": "8b94aba7-b695-4054-cc8f-44e88fabe4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  (100, 28, 28)\n",
            "convolution  (100, 32, 26, 26)\n",
            "activation:  (100, 32, 26, 26)\n",
            "max pooling:  (100, 32, 13, 13)\n",
            "flattened_output:  (100, 5408)\n",
            "fully connected layer 1: (100, 64)\n",
            "fully connected layer 2: (100, 10)\n",
            "Predicted values:  [7 2 1 0 4 1 4 9 6 9]\n",
            "Test Labels     :  [7 2 1 0 4 1 4 9 5 9]\n",
            "accuracy:  0.86\n"
          ]
        }
      ],
      "source": [
        "pred = forward_pass(test_images[:100], conv1_wt, conv1_bias, fc1_wt, fc1_bias, fc2_wt, fc2_bias)\n",
        "\n",
        "print(\"Predicted values: \", pred[:10])\n",
        "print(\"Test Labels     : \", test_labels[:10])\n",
        "print(\"accuracy: \", sum(pred[:100] == test_labels[:100])/len(pred[:100]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXBb7fl8ofql"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
